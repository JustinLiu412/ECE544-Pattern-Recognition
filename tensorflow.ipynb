{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Only need '%matplotlib inline' when running in ipython notebook.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(set_type):\n",
    "    \"\"\"Get data from files and storage them in a array. Return the data_set and label_set.\n",
    "    \n",
    "    set_type    the type of data set you want to build, including train dataset, dev dataset \n",
    "                and eval dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    data_path = {'train': 'train/lab/hw1train_labels.txt', 'dev': 'dev/lab/hw1dev_labels.txt', \\\n",
    "                 'eval': 'eval/lab/hw1eval_labels.txt'} \n",
    "\n",
    "    label_array = np.loadtxt(data_path[set_type], dtype='string')\n",
    "\n",
    "    #creat empty arrays to insert label and data\n",
    "    label_set = np.zeros([len(label_array), 2])\n",
    "    data_set = np.zeros([len(label_array), 16])\n",
    "\n",
    "    #the first column of the label file is the label,\n",
    "    #the second column is the corresbonding data file nam\n",
    "    for i in range(len(label_set)): \n",
    "        \n",
    "        #build the label set\n",
    "        if int(label_array[i][0]) == 0:\n",
    "            label_set[i][0] = 1 #insert label into label_set\n",
    "        else:\n",
    "            label_set[i][1] = 1\n",
    "            \n",
    "        #build the data set\n",
    "        with open(label_array[i][1]) as data_file:\n",
    "            data = data_file.readlines()[0].split() #find the data accoding to label\n",
    "        for j in range(len(data)):\n",
    "            data_set[i][j] = data[j] #insert data into the dataset\n",
    "            \n",
    "    data_set, label_set = nan_check(data_set, label_set) #delete the rows containing 'nan'\n",
    "    \n",
    "    return data_set, label_set #return the data set and label set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nan_check(data, label):\n",
    "    \"\"\"Find out the rows in datasets and delete these rows\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    nan_rows = np.array(0); #define an array containg the no. of rows having 'nan'\n",
    "    \n",
    "    #collect all the numbers of 'nan'-data rows\n",
    "    for i in range(len(data)):\n",
    "        for j in range(16):\n",
    "            if str(data[i][j]) == 'nan':\n",
    "                nan_rows = np.append(nan_rows, i)\n",
    "    nan_rows = np.delete(nan_rows, 0) #delete the first element of nan_rows which was made to fit the append()\n",
    "    \n",
    "    return np.delete(data, nan_rows, 0), np.delete(label, nan_rows, 0) #output the dataset whose 'nan'-data rows have been deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(data_set, label_set):\n",
    "    \"\"\"Randomly shuffle the data and label\n",
    "    \n",
    "    data_set    the data samples\n",
    "    \n",
    "    label_set   the lables\n",
    "    \"\"\"\n",
    "    \n",
    "    shuffled_data = np.zeros((data_set.shape))\n",
    "    shuffled_label = np.zeros((label_set.shape))\n",
    "    idx = np.array(xrange(len(label_set)))\n",
    "    random.shuffle(idx)\n",
    "    i = 0\n",
    "    for j in idx:\n",
    "        shuffled_data[i] = data_set[int(j)]\n",
    "        shuffled_label[i] = label_set[int(j)]\n",
    "        i += 1\n",
    "    return shuffled_data, shuffled_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8774, 16) (8774, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label = get_data('train')\n",
    "train_data, train_label = shuffle(train_data, train_label)\n",
    "print train_data.shape, train_label.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0: 0.604748\n",
      "Loss at step 20: 0.568247\n",
      "Loss at step 40: 0.539844\n",
      "Loss at step 60: 0.517532\n",
      "Loss at step 80: 0.499523\n",
      "Loss at step 100: 0.484421\n",
      "Loss at step 120: 0.471251\n",
      "Loss at step 140: 0.459400\n",
      "Loss at step 160: 0.448505\n",
      "Loss at step 180: 0.438349\n",
      "Loss at step 200: 0.428799\n",
      "Loss at step 220: 0.419767\n",
      "Loss at step 240: 0.411188\n",
      "Loss at step 260: 0.403012\n",
      "Loss at step 280: 0.395200\n",
      "Loss at step 300: 0.387720\n",
      "Loss at step 320: 0.380548\n",
      "Loss at step 340: 0.373663\n",
      "Loss at step 360: 0.367046\n",
      "Loss at step 380: 0.360684\n",
      "Loss at step 400: 0.354562\n",
      "Loss at step 420: 0.348667\n",
      "Loss at step 440: 0.342989\n",
      "Loss at step 460: 0.337514\n",
      "Loss at step 480: 0.332235\n",
      "Loss at step 500: 0.327142\n",
      "Loss at step 520: 0.322230\n",
      "Loss at step 540: 0.317491\n",
      "Loss at step 560: 0.312920\n",
      "Loss at step 580: 0.308512\n",
      "Loss at step 600: 0.304261\n",
      "Loss at step 620: 0.300163\n",
      "Loss at step 640: 0.296212\n",
      "Loss at step 660: 0.292403\n",
      "Loss at step 680: 0.288729\n",
      "Loss at step 700: 0.285186\n",
      "Loss at step 720: 0.281767\n",
      "Loss at step 740: 0.278467\n",
      "Loss at step 760: 0.275279\n",
      "Loss at step 780: 0.272198\n",
      "Loss at step 800: 0.269220\n",
      "Loss at step 820: 0.266336\n",
      "Loss at step 840: 0.263544\n",
      "Loss at step 860: 0.260837\n",
      "Loss at step 880: 0.258212\n",
      "Loss at step 900: 0.255664\n",
      "Loss at step 920: 0.253188\n",
      "Loss at step 940: 0.250781\n",
      "Loss at step 960: 0.248440\n",
      "Loss at step 980: 0.246161\n",
      "Loss at step 1000: 0.243942\n",
      "Loss at step 1020: 0.241778\n",
      "Loss at step 1040: 0.239669\n",
      "Loss at step 1060: 0.237612\n",
      "Loss at step 1080: 0.235605\n",
      "Loss at step 1100: 0.233645\n",
      "Loss at step 1120: 0.231732\n",
      "Loss at step 1140: 0.229863\n",
      "Loss at step 1160: 0.228037\n",
      "Loss at step 1180: 0.226253\n",
      "Loss at step 1200: 0.224510\n",
      "Loss at step 1220: 0.222806\n",
      "Loss at step 1240: 0.221140\n",
      "Loss at step 1260: 0.219511\n",
      "Loss at step 1280: 0.217918\n",
      "Loss at step 1300: 0.216362\n",
      "Loss at step 1320: 0.214839\n",
      "Loss at step 1340: 0.213349\n",
      "Loss at step 1360: 0.211893\n",
      "Loss at step 1380: 0.210468\n",
      "Loss at step 1400: 0.209074\n",
      "Loss at step 1420: 0.207710\n",
      "Loss at step 1440: 0.206375\n",
      "Loss at step 1460: 0.205070\n",
      "Loss at step 1480: 0.203792\n",
      "Loss at step 1500: 0.202542\n",
      "Loss at step 1520: 0.201318\n",
      "Loss at step 1540: 0.200120\n",
      "Loss at step 1560: 0.198947\n",
      "Loss at step 1580: 0.197799\n",
      "Loss at step 1600: 0.196675\n",
      "Loss at step 1620: 0.195575\n",
      "Loss at step 1640: 0.194497\n",
      "Loss at step 1660: 0.193441\n",
      "Loss at step 1680: 0.192407\n",
      "Loss at step 1700: 0.191394\n",
      "Loss at step 1720: 0.190402\n",
      "Loss at step 1740: 0.189430\n",
      "Loss at step 1760: 0.188478\n",
      "Loss at step 1780: 0.187544\n",
      "Loss at step 1800: 0.186629\n",
      "Loss at step 1820: 0.185733\n",
      "Loss at step 1840: 0.184854\n",
      "Loss at step 1860: 0.183992\n",
      "Loss at step 1880: 0.183147\n",
      "Loss at step 1900: 0.182319\n",
      "Loss at step 1920: 0.181506\n",
      "Loss at step 1940: 0.180709\n",
      "Loss at step 1960: 0.179928\n",
      "Loss at step 1980: 0.179161\n",
      "[[ 0.7798447   0.90682095]\n",
      " [ 0.09502781 -0.11867212]\n",
      " [ 1.48037529 -1.89145017]\n",
      " [-0.59940928  0.88453853]\n",
      " [-1.62116373  0.61867577]\n",
      " [ 1.10302293  1.66021883]\n",
      " [-0.88480401  0.11382718]\n",
      " [-0.96921813  1.47953212]\n",
      " [-0.53250557  0.73162872]\n",
      " [ 0.08707391 -1.26757014]\n",
      " [-0.43316394 -0.58046705]\n",
      " [ 0.10472714 -0.60401243]\n",
      " [ 0.85221189  0.63280702]\n",
      " [ 0.91810143  0.82162541]\n",
      " [ 1.29165101 -1.09378278]\n",
      " [-0.38010177  1.77524412]]\n"
     ]
    }
   ],
   "source": [
    "x_placeholder = tf.placeholder(tf.float32, [None, 16])\n",
    "y_placeholder = tf.placeholder(tf.float32, [None, 2])\n",
    "w = tf.Variable(tf.random_normal([16, 2]))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "y_hat = tf.nn.softmax(tf.matmul(x_placeholder, w) + b)\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(y_placeholder-y_hat)) / train_data.shape[0]\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "y_error = []\n",
    "\n",
    "for step in range(2000):\n",
    "    feed_dict = {x_placeholder: train_data, y_placeholder: train_label}\n",
    "    sess.run(train_step, feed_dict=feed_dict)\n",
    "    loss_np = sess.run(loss, feed_dict=feed_dict)\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(\"Loss at step %d: %f\" % (step, loss_np))\n",
    "        y_error.append(loss_np)\n",
    "print sess.run(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x126c5b310>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1261a2250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x_axis = np.arange(0, 2000, 20)\n",
    "\n",
    "plt.plot(x_axis, y_error,'r', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
